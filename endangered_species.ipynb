{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffad2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/25 21:15:44 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "24/04/25 21:15:44 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "24/04/25 21:15:44 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/04/25 21:15:44 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-------+--------+--------------------+--------------------+------------+---------------+-----------------+--------------------+------------+\n",
      "|               title|         description|              seller|            location|             country|  price|currency|                  id|                 url|      domain|predicted_label|            match|         animal_name|product_type|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-------+--------+--------------------+--------------------+------------+---------------+-----------------+--------------------+------------+\n",
      "|10 OSTRICH FEATHE...|10 OSTRICH Feathe...|       thefeatherguy|Flushing, New Yor...|       United States|  70.99|     USD|4585214d-b4d7-4c0...|http://picclick.c...|picclick.com|            1.0|          Ostrich|             Ostrich|     feather|\n",
      "|1 PCS REAL Ostric...|1 Pcs Real Ostric...|          benel_7507|        shenzhen, CN|People’s Republic...|   53.0|     USD|fcb9fb2d-a260-446...|http://picclick.c...|picclick.com|            1.0|          Ostrich|             Ostrich|       skull|\n",
      "|ðŞ\"¥ðŞŠˆMEGALODON...|ðŞ\"¥ðŞŠˆMegalodon...|    fossils_from_ray|Battleboro, North...|       United States|   30.0|     USD|3b76c636-fa9f-492...|http://picclick.c...|picclick.com|            1.0|            shark|         Silky shark|       Teeth|\n",
      "|1.25 INCH SAND Ti...|1.25 inch Sand Ti...|           supete-28|Saint Paul, Minne...|Republic of Trini...|   25.0|     USD|6ee420cb-94f3-4bd...|http://picclick.c...|picclick.com|            1.0| Sand tiger shark|    Sand tiger shark|       tooth|\n",
      "|0.92\" CARCHARHINU...|0.92\" Carcharhinu...|      blueskyfossils|Sarasota, Florida...|       United States|   7.99|     USD|5744e9e6-d378-4e1...|http://picclick.c...|picclick.com|            1.0|     Carcharhinus|Carcharhinus falc...|       tooth|\n",
      "|10 BIG EYE Diablo...|10 Big Eye Diablo...|          goodwin808|Port Saint Lucie,...|Oriental Republic...|  16.69|     USD|1acc569f-998b-447...|http://picclick.c...|picclick.com|            1.0|          Redfish|             Redfish|        null|\n",
      "|(4) 1.5 OZ Silver...|(4) 1.5 oz Silver...|         welloverpar|   Vernon, Texas, US|       United States|  180.0|     USD|ca85022a-122b-454...|http://picclick.c...|picclick.com|            1.0|            white|   Great white shark|        null|\n",
      "|10 OSTRICH FEATHE...|10 OSTRICH Feathe...|       thefeatherguy|Flushing, New Yor...|       United States| 103.99|     USD|a3c9ad4b-13af-4da...|http://picclick.c...|picclick.com|            1.0|          Ostrich|             Ostrich|        wing|\n",
      "|Ìî•MEGALODON SHA...|Ìî•Megalodon Sha...|    fossils_from_ray|Battleboro, North...|       United States|   12.0|     USD|0912bc47-e124-416...|http://picclick.c...|picclick.com|            1.0|            shark|         Silky shark|       tooth|\n",
      "|10 FOSSIL  Shark ...|10 Fossil Shark T...|omnifariousartifacts|Asheville, North ...|       United States|  14.95|     USD|923125d5-7727-402...|http://picclick.c...|picclick.com|            1.0|            shark|         Silky shark|       Teeth|\n",
      "|Laurence Le Const...|For Sale on 1stDi...|                null|           Paris, FR|  Republic of France|1473.05|     USD|eb492587-0242-42b...|https://www.1stdi...| 1stdibs.com|            1.0|            white|   Great white shark|        null|\n",
      "|1-11/16 INCH GREA...|1-11/16 inch GREA...|        toothsleuth0|Charlotte, North ...|Saint Vincent and...|   44.0|     USD|fb02072c-f345-45a...|http://picclick.c...|picclick.com|            1.0|Great white shark|   Great white shark|       tooth|\n",
      "|1/2 LB+ MEGALODON...|1/2 lb+ Megalodon...|          tooffinder| Oviedo, Florida, US|  Dominican Republic|  125.0|     USD|536ec5bb-a0d1-4ef...|http://picclick.c...|picclick.com|            1.0|            shark|         Silky shark|       tooth|\n",
      "|1 1/4\" GENUINE Ha...|1 1/4\" Genuine Ha...|  lone_star_treasure|  El Paso, Texas, US|       United States|  135.0|     USD|3f6634fa-30cf-473...|http://picclick.c...|picclick.com|            1.0|          Ostrich|             Ostrich|       quill|\n",
      "|Ìî•̶àMEGALODON ...|Ìî•̶àMegalodon ...|    fossils_from_ray|Battleboro, North...|       United States|  120.0|     USD|fd9a9103-5212-47c...|http://picclick.c...|picclick.com|            1.0|            shark|         Silky shark|       tooth|\n",
      "|Ìî•OTODUS OBLIQU...|Ìî•Otodus obliqu...|    fossils_from_ray|Battleboro, North...|       United States|   80.0|     USD|e71bfc15-d9da-4cf...|http://picclick.c...|picclick.com|            1.0|            shark|         Silky shark|       tooth|\n",
      "| FOSSIL GREAT WHI...|Fossil Great Whit...|       fossilsonline| Venice, Florida, US|    Italian Republic|  102.0|     USD|e3cc9c9f-6ab2-4fb...|http://picclick.c...|picclick.com|            1.0|Great white shark|   Great white shark|       tooth|\n",
      "|10 HTLURECO BULLE...|10 HTLURECO Bulle...|            htlureco|Horseheads, New Y...|       United States|  19.84|     USD|83a1c24f-978c-4eb...|http://picclick.c...|picclick.com|            1.0|          Redfish|             Redfish|        null|\n",
      "|16.5\" ANTIQUE MIN...|16.5\" Antique min...|             aping30|         NANYANG, CN|People’s Republic...| 1105.0|     USD|15a8804f-c9e4-4ab...|http://picclick.c...|picclick.com|            1.0|            white|   Great white shark|        null|\n",
      "|METAL 18\" WIDE Tr...|Metal 18\" Wide Tr...|         warnerve777|Fort Worth, Texas...|       United States|   58.0|     USD|413eb5b2-5915-434...|http://picclick.c...|picclick.com|            1.0|            shark|         Silky shark|        null|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-------+--------+--------------------+--------------------+------------+---------------+-----------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#vv2289  - Vamshi\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from csv import reader\n",
    "\n",
    "cf = SparkConf()\n",
    "cf.set(\"spark.submit.deployMode\", \"client\")\n",
    "sc = SparkContext.getOrCreate(cf)\n",
    "    \n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "csv_path = \"/shared/dataWildlife/filtered.csv\"\n",
    "\n",
    "df =spark.read.option(\"escape\", \"\\\"\").option('quote',\"\\\"\").option(\"multiline\", True).csv(csv_path, inferSchema=True, header=True)\n",
    "\n",
    "df_filtered = df.filter(df[\"animal_name\"] != \"\")\n",
    "\n",
    "df_filtered.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54e16ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- seller: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- predicted_label: double (nullable = true)\n",
      " |-- match: string (nullable = true)\n",
      " |-- animal_name: string (nullable = true)\n",
      " |-- product_type: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|animal_name              |\n",
      "+-------------------------+\n",
      "|Halibut                  |\n",
      "|Sebastes fasciatus       |\n",
      "|Silky shark              |\n",
      "|Wolf                     |\n",
      "|Hippoglossus hippoglossus|\n",
      "|Calathus lundbladi       |\n",
      "|Struthio camelus         |\n",
      "|Caiman latirostris       |\n",
      "|Redfish                  |\n",
      "|Nile crocodile           |\n",
      "|Ground beetle            |\n",
      "|Sand tiger shark         |\n",
      "|Carcharias taurus        |\n",
      "|Carcharhinus falciformis |\n",
      "|Great white shark        |\n",
      "|Canis lupus              |\n",
      "|Crocodylus niloticus     |\n",
      "|Carcharhinus longimanus  |\n",
      "|Ostrich                  |\n",
      "+-------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_filtered.printSchema()\n",
    "\n",
    "\n",
    "unique_names_df = df_filtered.filter(df_filtered[\"animal_name\"].isNotNull() & (df_filtered[\"animal_name\"] != \"\")).select(\"animal_name\").distinct()\n",
    "\n",
    "unique_names_df.show(truncate=False)\n",
    "unique_names = [row['animal_name'] for row in unique_names_df.collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "236f97d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.23.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (3.7.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/miniconda3/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/miniconda3/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/miniconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.18.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Downloading openai-1.23.6-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydantic-core, h11, distro, annotated-types, pydantic, httpcore, httpx, openai\n",
      "\u001b[33m  WARNING: The script distro is installed in '/home/vv2289_nyu_edu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/home/vv2289_nyu_edu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script openai is installed in '/home/vv2289_nyu_edu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.6.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.6 pydantic-2.7.1 pydantic-core-2.18.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.92-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.92 (from boto3)\n",
      "  Downloading botocore-1.34.92-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from botocore<1.35.0,>=1.34.92->boto3) (2.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/miniconda3/lib/python3.8/site-packages (from botocore<1.35.0,>=1.34.92->boto3) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.92->boto3) (1.16.0)\n",
      "Downloading boto3-1.34.92-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.92-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.34.92 botocore-1.34.92 jmespath-1.0.1 s3transfer-0.10.1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f7850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (1.23.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/miniconda3/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/miniconda3/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/miniconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: boto3 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (1.34.92)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.92 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from boto3) (1.34.92)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from botocore<1.35.0,>=1.34.92->boto3) (2.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/miniconda3/lib/python3.8/site-packages (from botocore<1.35.0,>=1.34.92->boto3) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.92->boto3) (1.16.0)\n",
      "Halibut: Endangered\n",
      "Sebastes fasciatus: Endangered\n",
      "Silky shark: Not Endangered\n",
      "Wolf: Not Endangered\n",
      "Hippoglossus hippoglossus: Not Endangered\n",
      "Calathus lundbladi: Not Endangered\n",
      "Struthio camelus: Not Endangered\n",
      "Caiman latirostris: Not Endangered\n",
      "Redfish: Not Endangered\n",
      "Nile crocodile: Not Endangered\n",
      "Ground beetle: Endangered\n",
      "Sand tiger shark: Not Endangered\n",
      "Carcharias taurus: Not Endangered\n",
      "Carcharhinus falciformis: Endangered\n",
      "Great white shark: Not Endangered\n",
      "Canis lupus: Endangered\n",
      "Crocodylus niloticus: Not Endangered\n",
      "Carcharhinus longimanus: Endangered\n",
      "Ostrich: Not Endangered\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/shared/dataWildlife/animal_info.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/shared/dataWildlife/animal_info.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Check the DataFrame to make sure it's what you expect\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(df1\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py:3387\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3376\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3378\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3379\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3380\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3384\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3385\u001b[0m )\n\u001b[0;32m-> 3387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3392\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:1083\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1065\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1066\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1082\u001b[0m )\n\u001b[0;32m-> 1083\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py:228\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    239\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/pandas/io/common.py:647\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m         errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/shared/dataWildlife/animal_info.csv'"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install boto3\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import openai\n",
    "import json\n",
    "\n",
    "def check_species_status(species_name, api_key):\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    system_message = \"\"\"\n",
    "    You are a conservation expert with access to the latest IUCN Red List data. Determine whether the specified animal species is currently considered endangered, critically endangered, or least concern according to the IUCN Red List.\n",
    "    \"\"\"\n",
    "\n",
    "    user_message = species_name\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content.strip().lower()\n",
    "        is_endangered = 'endangered' in result or 'critically endangered' in result or 'threatened' in result\n",
    "        return is_endangered\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying OpenAI about species status: {e}\")\n",
    "        return None\n",
    "\n",
    "for name in unique_names:\n",
    "    \n",
    "    endangered = check_species_status(name, api_key)\n",
    "    status = 'Endangered' if endangered else 'Not Endangered'\n",
    "    if endangered is not None:\n",
    "        print(f\"{name}: {status}\")\n",
    "    else:\n",
    "        print(f\"{name}: Unable to determine status\")\n",
    "\n",
    "        \n",
    "results = []\n",
    "count=0;\n",
    "api_key=\"xxxxxxxxx\"\n",
    "for name in unique_names:\n",
    "    count+=1\n",
    "    if(count>3): \n",
    "        break\n",
    "    endangered = check_species_status(name, api_key)\n",
    "    status = 'Endangered' if endangered else 'Not Endangered'\n",
    "    if endangered is not None:\n",
    "        results.append({'animal_name': name, 'status': status})\n",
    "\n",
    "df1 = pd.DataFrame(results)\n",
    "\n",
    "df1.to_csv('animal_info.csv', header=True, index=False)\n",
    "\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c9544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  animal_name          status\n",
      "0                     Halibut  Not Endangered\n",
      "1          Sebastes fasciatus  Not Endangered\n",
      "2                 Silky shark      Endangered\n",
      "3                        Wolf  Not Endangered\n",
      "4   Hippoglossus hippoglossus  Not Endangered\n",
      "5          Calathus lundbladi  Not Endangered\n",
      "6            Struthio camelus  Not Endangered\n",
      "7          Caiman latirostris  Not Endangered\n",
      "8                     Redfish  Not Endangered\n",
      "9              Nile crocodile  Not Endangered\n",
      "10              Ground beetle      Endangered\n",
      "11           Sand tiger shark  Not Endangered\n",
      "12          Carcharias taurus  Not Endangered\n",
      "13   Carcharhinus falciformis      Endangered\n",
      "14          Great white shark  Not Endangered\n",
      "15                Canis lupus      Endangered\n",
      "16       Crocodylus niloticus  Not Endangered\n",
      "17    Carcharhinus longimanus      Endangered\n",
      "18                    Ostrich  Not Endangered\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install boto3\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from csv import reader\n",
    "\n",
    "cf = SparkConf()\n",
    "cf.set(\"spark.submit.deployMode\", \"client\")\n",
    "sc = SparkContext.getOrCreate(cf)\n",
    "    \n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "csv_path = \"/shared/dataWildlife/filtered.csv\"\n",
    "\n",
    "df =spark.read.option(\"escape\", \"\\\"\").option('quote',\"\\\"\").option(\"multiline\", True).csv(csv_path, inferSchema=True, header=True)\n",
    "\n",
    "df_filtered = df.filter(df[\"animal_name\"] != \"\")\n",
    "\n",
    "df_filtered.show()\n",
    "\n",
    "def check_species_status(species_name, api_key):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    system_message = \"\"\"\n",
    "    You are a conservation expert with access to the latest IUCN Red List data. Determine whether the specified animal species is currently considered endangered, critically endangered, or least concern according to the IUCN Red List.\n",
    "    \"\"\"\n",
    "    user_message = species_name\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip().lower()\n",
    "        is_endangered = 'endangered' in result or 'critically endangered' in result or 'threatened' in result\n",
    "        return is_endangered\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying OpenAI about species status: {e}\")\n",
    "        return None\n",
    "\n",
    "api_key=\"xxxxx\"\n",
    "if os.path.exists('animal_info.csv'):\n",
    "    known_data = pd.read_csv('animal_info.csv')\n",
    "else:\n",
    "    known_data = pd.DataFrame(columns=['animal_name', 'status'])\n",
    "\n",
    "new_data = []\n",
    "all_data = known_data.copy()\n",
    "for name in unique_names:\n",
    "    if name not in known_data['animal_name'].values:\n",
    "        endangered = check_species_status(name, api_key)\n",
    "        status = 'Endangered' if endangered else 'Not Endangered'\n",
    "        new_data.append({'animal_name': name, 'status': status})\n",
    "        if endangered is not None:\n",
    "            all_data = all_data.append({'animal_name': name, 'status': status}, ignore_index=True)\n",
    "\n",
    "if new_data:\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    new_df.to_csv('animal_info.csv', mode='a', header=not os.path.exists('animal_info.csv'), index=False)\n",
    "\n",
    "all_data.to_csv('output.csv', index=False)\n",
    "\n",
    "print(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d923e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c0238e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (1.23.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/miniconda3/lib/python3.8/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/miniconda3/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/miniconda3/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/miniconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: boto3 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (1.34.92)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.92 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from boto3) (1.34.92)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/vv2289_nyu_edu/.local/lib/python3.8/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from botocore<1.35.0,>=1.34.92->boto3) (2.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/miniconda3/lib/python3.8/site-packages (from botocore<1.35.0,>=1.34.92->boto3) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.92->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install boto3\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from csv import reader\n",
    "\n",
    "cf = SparkConf()\n",
    "cf.set(\"spark.submit.deployMode\", \"client\")\n",
    "sc = SparkContext.getOrCreate(cf)\n",
    "    \n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "csv_path = \"/shared/dataWildlife/filtered.csv\"\n",
    "\n",
    "df =spark.read.option(\"escape\", \"\\\"\").option('quote',\"\\\"\").option(\"multiline\", True).csv(csv_path, inferSchema=True, header=True)\n",
    "\n",
    "df_filtered = df.filter(df[\"animal_name\"] != \"\")\n",
    "\n",
    "unique_names_df = df_filtered.filter(df_filtered[\"animal_name\"].isNotNull() & (df_filtered[\"animal_name\"] != \"\")).select(\"animal_name\").distinct()\n",
    "\n",
    "unique_names = [row['animal_name'] for row in unique_names_df.collect()]\n",
    "\n",
    "\n",
    "def check_species_status(species_name, api_key):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    system_message = \"\"\"\n",
    "    You are a conservation expert with access to the latest IUCN Red List data. Determine whether the specified animal species is currently considered endangered, critically endangered, or least concern according to the IUCN Red List.\n",
    "    \"\"\"\n",
    "    user_message = species_name\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ]\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip().lower()\n",
    "        is_endangered = 'endangered' in result or 'critically endangered' in result or 'threatened' in result\n",
    "        return is_endangered\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying OpenAI about species status: {e}\")\n",
    "        return None\n",
    "\n",
    "api_key=\"xxxxxx\"\n",
    "if os.path.exists('animal_info.csv'):\n",
    "    known_data = pd.read_csv('animal_info.csv')\n",
    "else:\n",
    "    known_data = pd.DataFrame(columns=['animal_name', 'status'])\n",
    "\n",
    "new_data = []\n",
    "all_data = known_data.copy()\n",
    "for name in unique_names:\n",
    "    if name not in known_data['animal_name'].values:\n",
    "        endangered = check_species_status(name, api_key)\n",
    "        status = 'Endangered' if endangered else 'Not Endangered'\n",
    "        new_data.append({'animal_name': name, 'status': status})\n",
    "        if endangered is not None:\n",
    "            all_data = all_data.append({'animal_name': name, 'status': status}, ignore_index=True)\n",
    "\n",
    "if new_data:\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    new_df.to_csv('animal_info.csv', mode='a', header=not os.path.exists('animal_info.csv'), index=False)\n",
    "\n",
    "all_data.to_csv('output.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d867f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
